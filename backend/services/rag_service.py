import openai
from typing import List
from models.chat_model import RAGResponse
from repositories.vector_repo import VectorRepository


class RAGService:
    def __init__(self):
        self.vector_repo = VectorRepository()
        self.embed_model = "text-embedding-ada-002"
        self.llm_model = "gpt-4"

    async def generate_response(self, question: str, chat_id: str, namespace: str = "mother_health",
                                **filters) -> RAGResponse:
        """
        Kucak-AI iÃ§in Ã¶zelleÅŸtirilmiÅŸ RAG servisi
        namespace: mother_health veya baby_development
        filters: pregnancy_week, baby_age_weeks gibi filtreler
        """
        try:
            # 1. GÃ¶mme vektÃ¶rÃ¼ oluÅŸtur
            query_embed = self._get_embedding(question)

            # 2. VektÃ¶r veritabanÄ±nda arama yap
            results = await self.vector_repo.query_vectors(
                vector=query_embed,
                namespace=namespace,
                filter=filters
            )

            # 3. BaÄŸlam dokÃ¼manÄ± oluÅŸtur
            context = self._build_context(results.matches)

            # 4. LLM'den yanÄ±t al
            response = await self._generate_llm_response(
                question=question,
                context=context,
                namespace=namespace,
                filters=filters
            )

            return RAGResponse(
                answer=response,
                references=[m.metadata['source'] for m in results.matches],
                suggested_actions=self._extract_suggested_actions(response)
            )
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Kucak-AI bilgi sistemi hatasÄ±: {str(e)}")

    def _get_embedding(self, text: str) -> List[float]:
        return openai.Embedding.create(
            input=[text],
            model=self.embed_model
        ).data[0].embedding

    def _build_context(self, matches) -> str:
        context = []
        for m in matches:
            source = m.metadata.get('source', 'Bilinmeyen Kaynak')
            text = m.metadata['text']
            context.append(f"ğŸ“Œ Kaynak: {source}\n{text}")

            # Hamilelik veya bebek haftasÄ± bilgisi ekle
            if 'pregnancy_week' in m.metadata:
                context.append(f"ğŸ”¹ Ä°lgili Gebelik HaftasÄ±: {m.metadata['pregnancy_week']}")
            elif 'baby_age_weeks' in m.metadata:
                context.append(f"ğŸ‘¶ Bebek YaÅŸÄ±: {m.metadata['baby_age_weeks']} haftalÄ±k")

        return "\n\n".join(context)

    async def _generate_llm_response(self, question: str, context: str, namespace: str, filters: dict) -> str:
        system_prompt = self._get_system_prompt(namespace, filters)

        response = openai.ChatCompletion.create(
            model=self.llm_model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"BaÄŸlam:\n{context}\n\nSoru: {question}"}
            ],
            temperature=0.3,
            max_tokens=1200
        )
        return response.choices[0].message.content

    def _get_system_prompt(self, namespace: str, filters: dict) -> str:
        if namespace == "baby_development":
            baby_age = filters.get('baby_age_weeks', 'bilinmiyor')
            return f"""
            Sen Kucak-AI'nÄ±n yenidoÄŸan bakÄ±m uzmanÄ±sÄ±n. {baby_age} haftalÄ±k bebekler iÃ§in:
            - Bilimsel temelli geliÅŸim bilgileri ver
            - Ebeveynlere pratik Ã¶neriler sun
            - Acil durum belirtilerinde doktora yÃ¶nlendir
            - WHO'nun bebek bakÄ±mÄ± kÄ±lavuzlarÄ±na atÄ±f yap
            """
        else:
            pregnancy_week = filters.get('pregnancy_week', 'bilinmiyor')
            return f"""
            Sen Kucak-AI'nÄ±n gebelik uzmanÄ±sÄ±n. {pregnancy_week}. hafta iÃ§in:
            - Annenin fiziksel ve duygusal deÄŸiÅŸimlerini aÃ§Ä±kla
            - Bebek geliÅŸimini haftaya Ã¶zel anlat
            - Beslenme ve egzersiz Ã¶nerileri ver
            - Risk belirtilerinde hemen saÄŸlÄ±k kuruluÅŸuna yÃ¶nlendir
            """

    def _extract_suggested_actions(self, response: str) -> List[str]:
        # YanÄ±ttan otomatik eylem Ã¶nerileri Ã§Ä±kar
        actions = []
        if "doktora baÅŸvurun" in response.lower():
            actions.append("ACÄ°L DURUM: En yakÄ±n saÄŸlÄ±k kuruluÅŸuna gitmelisiniz")
        if "beslenme" in response.lower():
            actions.append("Ã–NERÄ°: Beslenme planÄ±nÄ±zÄ± gÃ¶zden geÃ§irin")
        return actions